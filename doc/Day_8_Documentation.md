# ğŸ§  DvaitAI â€“ Day 8 Documentation

## ğŸ“… Overview
**Date:** November 9, 2025  
**Phase:** M.Tech Project â€“ *Pedestrian-Aware Autonomous Navigation (DvaitAI Phase 2)*  
**Focus:** Project Setup + Dataset Preparation + YOLOv5 Integration  
**Status:** âœ… All core goals completed

---

## ğŸš€ Completed Tasks

| # | Task | Description | Output | Duration | Status |
|---|------|--------------|---------|-----------|--------|
| **1ï¸âƒ£** | **Project Setup & Architecture** | Created new ROS2 workspace `ros2_ws_nav` and initialized package `pedestrian_nav_ai`. | ROS2 package + `setup.py`, `package.xml`, and node structure ready. | 1 hr | âœ… |
| **2ï¸âƒ£** | **Dataset & Framework Prep** | Set up datasets PIE, KITTI, and nuScenes. Configured PyTorch, OpenCV, and YOLOv5 environments. | Dataset pipeline verified and tested. | 2 hrs | âœ… |
| **3ï¸âƒ£** | **YOLOv5 Pedestrian Detection Node** | Integrated pre-trained YOLOv5 model into ROS2 node that publishes detection results. | `/bounding_boxes` topic publishing successfully with live inference. | 2 hrs | âœ… |
| **4ï¸âƒ£** | **Documentation & GitHub Update** | Created documentation, updated repo README, and committed setup scripts. | Synced with GitHub under `pedestrian_nav_ai` repo. | 1 hr | âœ… |

---

## âš™ï¸ Technical Setup Process

### ğŸ§© ROS2 Workspace Setup
```bash
# Create a new ROS2 workspace
mkdir -p ~/Music/DvaitAI/ros2_ws/src
cd ~/Music/DvaitAI/ros2_ws

# Initialize pedestrian navigation package
cd src
ros2 pkg create --build-type ament_python pedestrian_nav_ai
cd ..

# Build workspace
colcon build --symlink-install
source install/setup.bash
```

### ğŸ“¦ Dependencies Installed
```bash
sudo apt install ros-humble-rviz2 ros-humble-cv-bridge python3-colcon-common-extensions
pip install torch torchvision opencv-python ultralytics pandas matplotlib
```

### ğŸ§  YOLOv5 Integration
```bash
# Clone YOLOv5 into the project folder
cd ~/ros2_ws_nav/src/pedestrian_nav_ai
git clone https://github.com/ultralytics/yolov5.git

# Load pretrained model in ROS2 node (Python)
from ultralytics import YOLO

model = YOLO('yolov5s.pt')
results = model(source='0')  # webcam or video stream
```
The model publishes detection results to ROS2 topic `/bounding_boxes` as `std_msgs/String` JSON-encoded messages.

## ğŸ“ Repository Structure
```
pedestrian_nav_ai/
â”œâ”€â”€ pedestrian_nav_ai/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ detection_node.py      # YOLOv5 + ROS2 integration
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ converter.py       # KITTI/PIE dataset format converter
â”‚   â””â”€â”€ launch/
â”‚       â””â”€â”€ detection.launch.py
â”œâ”€â”€ package.xml
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

---

## ğŸ§  Learnings & Observations
- YOLOv5 performs well for pedestrian detection even on limited compute.  
- ROS2 + PyTorch integration requires multi-threaded callbacks to avoid message lag.  
- Dataset preprocessing pipelines differ between KITTI and PIE â€” custom converters were built.  

---

## ğŸ“Š Results Summary
- âœ… Live pedestrian detection using YOLOv5 integrated with ROS2 topics.  
- âœ… Dataset preprocessing and environment setup completed.  
- âœ… Visualization pipeline validated using RViz2.  

---

## ğŸ”— Next Steps (Day 9)
1ï¸âƒ£ Add real-time bounding box visualization overlay on live video stream.  
2ï¸âƒ£ Begin trajectory prediction module (LSTM/Kalman filter).  
3ï¸âƒ£ Start drafting M.Tech report section: *â€œPedestrian Detection & Dataset Integration.â€*  

---

## ğŸ’ª Motivation of the Day
> â€œClarity comes from structure. Every setup you complete today becomes the skeleton of tomorrowâ€™s intelligence.â€

---

## ğŸ“œ Summary
Day 8 marks the successful initiation of the M.Tech AI Navigation Project.  
ROS2 workspace, dataset preprocessing, and YOLOv5 integration have been completed.  
The system can now detect pedestrians live and publish detection data for further trajectory prediction.

---
